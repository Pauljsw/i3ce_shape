# ğŸ“Š ShapeLLM Scaffold Missing Detection - ì¢…í•© ë³´ê³ ì„œ

**ë‚ ì§œ:** 2026-01-22
**í”„ë¡œì íŠ¸:** ë¹„ê³„ êµ¬ì¡°ë¬¼ ê²°ì† íƒì§€ ì‹œìŠ¤í…œ
**ëª¨ë¸:** ShapeLLM 7B + LoRA Fine-tuning

---

## ğŸ“‹ ëª©ì°¨

1. [ì „ì²´ íŒŒì´í”„ë¼ì¸ ê°œìš”](#1-ì „ì²´-íŒŒì´í”„ë¼ì¸-ê°œìš”)
2. [ë‹¨ê³„ 1: ë°ì´í„° ìƒì„±](#2-ë‹¨ê³„-1-ë°ì´í„°-ìƒì„±)
3. [ë‹¨ê³„ 2: ëª¨ë¸ í›ˆë ¨](#3-ë‹¨ê³„-2-ëª¨ë¸-í›ˆë ¨)
4. [ë‹¨ê³„ 3: ì¶”ë¡  ë°ì´í„° ìƒì„±](#4-ë‹¨ê³„-3-ì¶”ë¡ -ë°ì´í„°-ìƒì„±)
5. [ë‹¨ê³„ 4: ì„±ëŠ¥ ê²€ì¦](#5-ë‹¨ê³„-4-ì„±ëŠ¥-ê²€ì¦)
6. [ë°œê²¬ëœ ë¬¸ì œì ](#6-ë°œê²¬ëœ-ë¬¸ì œì )
7. [ê·¼ë³¸ ì›ì¸ ë¶„ì„](#7-ê·¼ë³¸-ì›ì¸-ë¶„ì„)
8. [í•™ìˆ ì  ë¶„ì„](#8-í•™ìˆ ì -ë¶„ì„)
9. [í•´ê²° ë°©ì•ˆ](#9-í•´ê²°-ë°©ì•ˆ)
10. [ì½”ë“œ ìˆ˜ì • ì´ë ¥](#10-ì½”ë“œ-ìˆ˜ì •-ì´ë ¥)

---

## 1. ì „ì²´ íŒŒì´í”„ë¼ì¸ ê°œìš”

```mermaid
graph LR
    A[Data Generation] --> B[Training]
    B --> C[Inference]
    C --> D[Evaluation]
    D --> E[Problem Discovery]
```

### 1.1 ì‚¬ìš©ëœ íŒŒì¼ êµ¬ì¡°

```
i3ce_shape/
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ modified_scaffold_generator_final_COMPLETE_fixed.py  # ë¹„ê³„ ìƒì„±ê¸°
â”‚   â”œâ”€â”€ missing_detection_dataset_final_COMPLETE_fixed.py    # ë°ì´í„°ì…‹ ìƒì„±
â”‚   â””â”€â”€ comprehensive_eval_missing.py                         # í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ finetune_lora_test.sh                                # í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ interactive_test.py                                   # ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸
â”œâ”€â”€ llava/eval/
â”‚   â””â”€â”€ model_vqa.py                                          # ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ playground/data/shapellm/scaffold_missing_complete/
    â”œâ”€â”€ pcs/                                                  # Point cloud files
    â”œâ”€â”€ question_missing.jsonl                                # ì§ˆë¬¸ ë°ì´í„°
    â”œâ”€â”€ gt_missing.jsonl                                      # Ground Truth
    â””â”€â”€ answers_missing.jsonl                                 # ëª¨ë¸ ì˜ˆì¸¡
```

---

## 2. ë‹¨ê³„ 1: ë°ì´í„° ìƒì„±

### 2.1 ì‹¤í–‰ ëª…ë ¹ì–´

```bash
python tools/missing_detection_dataset_final_COMPLETE_fixed.py \
  --num-scenes 3000 \
  --train-ratio 0.8 \
  --val-ratio 0.2 \
  --output-dir ./playground/data/shapellm/scaffold_missing_complete
```

### 2.2 ë°ì´í„° ìƒì„± í”„ë¡œì„¸ìŠ¤

#### 2.2.1 Scaffold ìƒì„± ë¡œì§ (`modified_scaffold_generator_final_COMPLETE_fixed.py`)

**í•µì‹¬ íŒŒë¼ë¯¸í„°:**
```python
# Line 1201-1207
config = {
    'num_bays': random.randint(2, 4),        # 2-4 bay
    'bay_width': random.uniform(1.5, 2.0),   # 1.5-2.0m
    'depth': random.uniform(1.2, 1.8),       # 1.2-1.8m
    'num_floors': random.randint(2, 4),      # 2-4 floor
    'floor_height': random.uniform(1.8, 2.2), # 1.8-2.2m
    'safety_status': random.choice(['safe', 'minor_defect', 'major_defect'])
}
```

**Point Cloud ìƒì„±:**

1. **Pipe (Beam/Post) ì  ìƒì„±** (Line 204-234):
```python
def generate_pipe_points(self, start_pos, end_pos, diameter, num_points=None):
    # ê¸¸ì´ ê¸°ë°˜ adaptive sampling (ìˆ˜ì •ë¨)
    if num_points is None:
        num_points = max(int(length * 100), 10)  # ê¸¸ì´ Ã— 100
        num_points = min(num_points, 200)         # ìµœëŒ€ 200

    # 8ê°œ ê°ë„ë¡œ ì›í†µí˜• í‘œí˜„
    for i in range(num_points):
        t = i / (num_points - 1)
        center = start_pos + t * direction

        for j in range(8):  # 8-corner cylinder
            angle = j * 2 * np.pi / 8
            offset = radius * (cos(angle) * perp1 + sin(angle) * perp2)
            noise = np.random.normal(0, 0.005, 3)  # Natural variation
            points.append(center + offset + noise)
```

2. **Platform ì  ìƒì„±** (Line 242-257):
```python
def generate_platform_points(self, center, width, length, num_points=None):
    # ë©´ì  ê¸°ë°˜ adaptive sampling (ìˆ˜ì •ë¨)
    if num_points is None:
        area = width * length
        num_points = max(int(area * 100), 50)
        num_points = min(num_points, 500)
```

3. **Point Cloud Normalization** (Line 1304-1319):
```python
# Step 1: Centering
centroid = np.mean(coord, axis=0)
coord_centered = coord - centroid

# Step 2: Scaling (max distance ~1.0)
max_distance = np.linalg.norm(coord_centered, axis=1).max()
scale = float(max_distance + 1e-12)
coord_scaled = coord_centered / scale

# Step 3: Random rotation (Z-axis, Â±45Â°)
Rz_deg = float(np.random.uniform(-45.0, 45.0))
theta = np.radians(Rz_deg)
R = np.array([[cos_t, -sin_t, 0], [sin_t, cos_t, 0], [0, 0, 1]])
coord_norm = (R @ coord_scaled.T).T
```

**ê²°ì† ì»´í¬ë„ŒíŠ¸ ìƒì„±:**

```python
# Line 448-497: Horizontal beam missing ì˜ˆì‹œ
if base_missing_rate > 0:
    num_to_remove = min(num_candidates, self.missing_quota - self.current_missing_count)

    if num_to_remove > 0:
        random.shuffle(all_horizontals)  # Randomize selection

        for i in range(num_to_remove):
            comp = all_horizontals[i]
            # Convert to missing marker (10ê°œ ì ë§Œ)
            marker_points = []
            for _ in range(10):
                noise = np.random.normal(0, 0.05, 3)
                marker_points.append(mid_pos + noise)

            # semantic_id=10 (missing marker)
            all_horizontals[i] = ScaffoldComponent(
                name=f"missing_horizontal_{...}",
                semantic_id=10,  # Missing marker
                points=marker_points,
                bbox=bbox,
                ...
            )
```

#### 2.2.2 Question ìƒì„± ë¡œì§ (`missing_detection_dataset_final_COMPLETE_fixed.py`)

**10ê°€ì§€ Question Type:**

```python
# Line 307-442 ì§ˆë¬¸ ìƒì„± íŒ¨í„´

# 1. _missing_summary (ê²°ì†ì´ ìˆëŠ” ê²½ìš°)
if missing_comps:
    question_text = f"<point>\nThis is a {scaffold_spec}. " \
                    "Are there any missing components? If so, provide their locations."
    # âš ï¸ "If so, provide their locations" - ê²°ì† ì•”ì‹œ!

# 2. _missing_none (ê²°ì†ì´ ì—†ëŠ” ê²½ìš°)
else:
    question_text = f"<point>\nThis is a {scaffold_spec}. " \
                    "Are there any missing components?"
    # âš ï¸ "locations" ë¬¸êµ¬ ì—†ìŒ - Data Leakage!

# 3-10. _missing_floor_X, _missing_bay_X, _missing_specific_X, etc.
# ëª¨ë‘ ë™ì¼í•œ íŒ¨í„´ìœ¼ë¡œ ìƒì„±
```

**GT Label ìƒì„±:**

```python
# Line 330, 335
if task_type == 'missing_detection_none':
    label = 'No'   # â† í•­ìƒ No
elif missing_comps:
    label = 'Yes'  # â† í•­ìƒ Yes
```

**BBox ì €ì¥:**

```python
# Line 336-346
valid_bboxes = []
for c in missing_comps:
    if c.bbox_norm is not None:  # Normalized bbox
        bbox_list = c.bbox_norm.tolist()  # 8-corner format
        valid_bboxes.append(bbox_list)
bboxes = valid_bboxes
```

### 2.3 ìƒì„±ëœ ë°ì´í„° êµ¬ì¡°

#### question_missing.jsonl
```json
{
  "question_id": "scaffold_02922_missing_summary",
  "point": "scaffold_02922.npy",
  "text": "This is a 4-bay, 2-row, 3-floor scaffold. Are there any missing components? If so, provide their locations.",
  "category": "scaffold"
}
```

#### gt_missing.jsonl
```json
{
  "question_id": "scaffold_02922_missing_summary",
  "point": "scaffold_02922.npy",
  "text": "Expected structure: 4-bay, 2-row, 3-floor scaffold has 10 vertical posts, 39 horizontal beams, 12 platforms.\nActual: 9 vertical posts, 37 horizontal beams, 11 platforms.\nMissing: 4 components...",
  "label": "Yes",
  "bboxes": [
    [[0.300, -0.217, 0.120], [0.347, -0.217, 0.120], ...],
    [[-0.446, 0.221, -0.563], ...],
    ...
  ],
  "category": "scaffold"
}
```

#### Point Cloud (.npy)
```python
# Shape: (N, 6) - x, y, z, r, g, b
# N ~= 50,000-150,000 points (random)
# Normalized: centered, scaled, rotated
# Color: Random RGB values (not meaningful)
```

### 2.4 ë°ì´í„°ì…‹ í†µê³„

```
Total scenes: 3000
â”œâ”€â”€ Train: 2400 scenes (80%)
â””â”€â”€ Val:   600 scenes (20%)

Questions per scene: ~16
â”œâ”€â”€ _missing_summary: 1
â”œâ”€â”€ _missing_none: 0-1 (ê²°ì† ì—†ì„ ë•Œë§Œ)
â”œâ”€â”€ _missing_floor_X: 0-4
â”œâ”€â”€ _missing_bay_X: 0-4
â”œâ”€â”€ _missing_specific_X: 0-10
â””â”€â”€ Others: varying

Total questions: ~48,000
â”œâ”€â”€ Train: ~38,400
â””â”€â”€ Val:   ~9,600
```

---

## 3. ë‹¨ê³„ 2: ëª¨ë¸ í›ˆë ¨

### 3.1 ì‹¤í–‰ ëª…ë ¹ì–´

```bash
bash scripts/finetune_lora_test.sh
```

### 3.2 í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš©

```bash
#!/bin/bash

# scripts/finetune_lora_test.sh

deepspeed llava/train/train_mem.py \
    --deepspeed ./scripts/zero2.json \
    --lora_enable True \
    --lora_r 128 \
    --lora_alpha 256 \
    --mm_projector_lr 2e-5 \
    --model_name_or_path qizekun/ShapeLLM_7B_gapartnet_v1.0 \
    --version v1 \
    --data_path ./playground/data/shapellm/scaffold_missing_complete/question_missing.jsonl \
    --point_folder ./playground/data/shapellm/scaffold_missing_complete/pcs \
    --point_tower qizekun/ShapeLLM_7B_gapartnet_v1.0 \
    --mm_projector_type mlp2x_gelu \
    --tune_mm_mlp_adapter False \
    --freeze_mm_mlp_adapter False \
    --freeze_backbone False \
    --point_select_layer -2 \
    --mm_use_point_start_end False \
    --mm_use_point_patch_token False \
    --bf16 True \
    --output_dir ./checkpoints/shapellm-7bs-scaffold-scaffold_i3ce2-lorascaffold-i3ce_260121_1800 \
    --num_train_epochs 3 \
    --per_device_train_batch_size 2 \
    --per_device_eval_batch_size 2 \
    --gradient_accumulation_steps 8 \
    --evaluation_strategy "no" \
    --save_strategy "steps" \
    --save_steps 100 \
    --save_total_limit 3 \
    --learning_rate 2e-4 \
    --weight_decay 0. \
    --warmup_ratio 0.03 \
    --lr_scheduler_type "cosine" \
    --logging_steps 1 \
    --tf32 True \
    --model_max_length 2048 \
    --gradient_checkpointing True \
    --dataloader_num_workers 4 \
    --lazy_preprocess True \
    --sample_points_num 10000 \
    --with_color True \
    --report_to tensorboard
```

### 3.3 í•µì‹¬ í›ˆë ¨ íŒŒë¼ë¯¸í„° ë¶„ì„

#### 3.3.1 LoRA Configuration

```python
--lora_enable True
--lora_r 128          # LoRA rank (parameter efficiency)
--lora_alpha 256      # LoRA scaling factor (alpha/r = 2.0)
--freeze_backbone False  # LLM backboneë„ í•™ìŠµ (LoRA)
```

**í•™ìˆ ì  ì›ë¦¬:**
- LoRA (Low-Rank Adaptation): Full fine-tuning ëŒ€ë¹„ ë©”ëª¨ë¦¬ íš¨ìœ¨ì 
- Rank 128: ì›ë³¸ weight Wì— ëŒ€í•´ W' = W + BA (B: 128Ã—d, A: dÃ—128)
- Alpha/r = 2.0: LoRA update scale

#### 3.3.2 Point Cloud Processing

```python
--sample_points_num 10000  # 10K points per sample
--with_color True          # 6 channels (x,y,z,r,g,b)
--point_tower qizekun/ShapeLLM_7B_gapartnet_v1.0
--point_select_layer -2    # Second-to-last layer features
```

**Point Cloud Encoder (ReCon V2):**
```python
# llava/model/multimodal_encoder/recon_encoder.py
class ReCon(nn.Module):
    def __init__(self):
        # Group point cloud: G512 Ã— S32
        self.group_divider = Group(num_group=512, group_size=32)

        # Position encoding (3D coordinates)
        self.pos_embed = nn.Sequential(
            nn.Linear(3, 128),
            nn.GELU(),
            nn.Linear(128, encoder_dims)
        )

        # Transformer blocks
        self.blocks = TransformerEncoder(...)

    def forward(self, pts):
        # pts: (B, N, 6) - x,y,z,r,g,b

        # Group into patches
        neighborhood, center = self.group_divider(pts[:, :, :3])
        # neighborhood: (B, 512, 32, 3)
        # center: (B, 512, 3)

        # Extract features
        group_features = self.encoder(neighborhood)  # Local
        pos_features = self.pos_embed(center)        # Position

        # Combine
        features = group_features + pos_features
        features = self.blocks(features)  # Transformer

        return features  # (B, 512, D)
```

#### 3.3.3 Training Hyperparameters

```python
--num_train_epochs 3
--per_device_train_batch_size 2
--gradient_accumulation_steps 8
# Effective batch size = 2 Ã— 8 Ã— num_gpus

--learning_rate 2e-4          # LoRA learning rate
--mm_projector_lr 2e-5        # Projector (10x smaller)
--warmup_ratio 0.03           # 3% warmup
--lr_scheduler_type "cosine"  # Cosine decay

--bf16 True                   # BFloat16 training
--gradient_checkpointing True # Memory optimization
```

**í•™ìˆ ì  ì›ë¦¬:**
- Differential learning rates: LoRA (2e-4) vs Projector (2e-5)
- Cosine schedule: LR smooth decay
- BF16: Numerical stability + speed

#### 3.3.4 Loss Function

```python
# llava/train/train.py (implicit)
# Causal Language Modeling Loss

loss = CrossEntropyLoss(
    input=model_output,    # Predicted tokens
    target=labels          # Ground truth text
)

# Text generationë§Œ í•™ìŠµ
# BBoxëŠ” text ì•ˆì— í¬í•¨ (e.g., "[[0.3, -0.2, 0.1], ...]")
# â†’ BBoxë¥¼ ë³„ë„ lossë¡œ í•™ìŠµí•˜ì§€ ì•ŠìŒ!
```

**âš ï¸ ì¤‘ìš”í•œ ë¬¸ì œ:**
- BBoxëŠ” ë‹¨ìˆœ text tokenìœ¼ë¡œ í•™ìŠµ
- 3D spatial loss ì—†ìŒ
- Text generation lossë§Œ ìˆìŒ
- â†’ BBox ì •í™•ë„ê°€ ë‚®ì€ ê·¼ë³¸ ì›ì¸!

### 3.4 ì‹¤ì œ í•™ìŠµ ê³¼ì •

```python
# Conversation format (v1)
{
    "conversations": [
        {
            "from": "human",
            "value": "<point>\nThis is a 4-bay scaffold. Are there any missing? If so, locations."
        },
        {
            "from": "gpt",
            "value": "Expected: 10 posts...\nMissing: [[0.3, -0.2, 0.1], ...]"
        }
    ]
}

# Training
input_ids = tokenize(prompt + answer)
labels = input_ids.clone()
labels[:len(prompt)] = -100  # Ignore prompt in loss

# Forward
point_features = point_encoder(point_cloud)  # (B, 512, D)
text_features = llm(input_ids, point_features)

# Loss
loss = CrossEntropy(text_features, labels)
```

**âš ï¸ Data Leakage ë°œìƒ ì§€ì :**
```python
# Promptì— ì´ë¯¸ íŒíŠ¸ í¬í•¨
"Are there any missing? If so, provide locations."  â† "locations" = Yes ì•”ì‹œ
"Are there any missing?"                             â† No ì•”ì‹œ

# ëª¨ë¸ì€ prompt patternë§Œ í•™ìŠµ ê°€ëŠ¥
# Point cloud ë³¼ í•„ìš” ì—†ìŒ!
```

---

## 4. ë‹¨ê³„ 3: ì¶”ë¡  ë°ì´í„° ìƒì„±

### 4.1 ì‹¤í–‰ ëª…ë ¹ì–´

```bash
python -m llava.eval.model_vqa \
  --model-path ./checkpoints/shapellm-7bs-scaffold-scaffold_i3ce2-lorascaffold-i3ce_260121_1800 \
  --model-base qizekun/ShapeLLM_7B_gapartnet_v1.0 \
  --question-file ./playground/data/shapellm/scaffold_missing_complete/question_missing.jsonl \
  --point-folder ./playground/data/shapellm/scaffold_missing_complete/pcs \
  --answers-file ./playground/data/shapellm/scaffold_missing_complete/answers_missing.jsonl \
  --conv-mode scaffold_missing \
  --temperature 0.05 \
  --num_beams 3
```

### 4.2 ì¶”ë¡  í”„ë¡œì„¸ìŠ¤ (`llava/eval/model_vqa.py`)

```python
# Line 27-91
def eval_model(args):
    # Load model
    tokenizer, model, context_len = load_pretrained_model(
        args.model_path,
        args.model_base,
        model_name
    )

    # Load questions
    questions = [json.loads(q) for q in open(args.question_file)]

    for line in questions:
        idx = line["question_id"]
        point_file = line["point"]
        qs = line["text"]  # â† Question textë§Œ ì‚¬ìš©!

        # Prepare input
        if model.config.mm_use_pt_start_end:
            qs = DEFAULT_PT_START_TOKEN + DEFAULT_POINT_TOKEN + DEFAULT_PT_END_TOKEN + '\n' + qs
        else:
            qs = DEFAULT_POINT_TOKEN + '\n' + qs

        # Tokenize
        input_ids = tokenizer_point_token(prompt, tokenizer, POINT_TOKEN_INDEX, ...)

        # Load point cloud
        point = load_pts(os.path.join(args.point_folder, point_file))
        pts_tensor = process_pts(point, model.config)  # (10000, 6)

        # Generate
        with torch.inference_mode():
            output_ids = model.generate(
                input_ids,
                points=pts_tensor,  # Point cloud
                do_sample=True if args.temperature > 0 and args.num_beams == 1 else False,
                temperature=args.temperature,  # 0.05 (ê±°ì˜ greedy)
                num_beams=args.num_beams,      # 3 (beam search)
                max_new_tokens=1024
            )

        # Decode
        outputs = tokenizer.batch_decode(output_ids, skip_special_tokens=True)[0]

        # Save
        ans_file.write(json.dumps({
            "question_id": idx,
            "prompt": cur_prompt,
            "text": outputs,
            "answer_id": shortuuid.uuid(),
            "model_id": model_name,
            "metadata": {}
        }))
```

**Generation Parameters:**
- `temperature=0.05`: ê±°ì˜ deterministic (greedy)
- `num_beams=3`: Beam search (top-3 candidates)
- `do_sample=False`: Greedy decoding (temp < threshold with beams)

### 4.3 ìƒì„±ëœ Answers ì˜ˆì‹œ

```json
{
  "question_id": "scaffold_02922_missing_summary",
  "prompt": "This is a 4-bay, 2-row, 3-floor scaffold. Are there any missing components? If so, provide their locations.",
  "text": "Expected structure: 4-bay, 2-row, 3-floor scaffold has 10 vertical posts, 39 horizontal beams, 12 platforms.\nActual: 9 vertical posts, 37 horizontal beams, 11 platforms.\nMissing: 3 components are missing:\n- Vertical post at column 3: [[0.33, -0.121, 0.111], ...]\n- Horizontal beam X at floor 2, bay 1: [[-0.153, 0.15, 0.301], ...]\n- Horizontal beam Y at floor 1, column 3: [[0.35, -0.105, -0.069], ...]",
  "answer_id": "EGN8cjDfrCKqM6gpyXdq53",
  "model_id": "shapellm-7bs-scaffold-scaffold_i3ce2-lorascaffold-i3ce_260121_1800",
  "metadata": {}
}
```

---

## 5. ë‹¨ê³„ 4: ì„±ëŠ¥ ê²€ì¦

### 5.1 ì‹¤í–‰ ëª…ë ¹ì–´

```bash
python tools/comprehensive_eval_missing.py \
  --gt-file ./playground/data/shapellm/scaffold_missing_complete/gt_missing.jsonl \
  --pred-file ./playground/data/shapellm/answers_missing.jsonl \
  --output-json ./eval_results.json \
  --output-report ./eval_report.txt
```

### 5.2 í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ êµ¬ì¡°

#### 5.2.1 Task 1: Binary Classification

```python
# Line 58-156
def eval_binary_classification(self):
    """Evaluate binary classification ONLY for *_missing_summary and *_missing_none"""

    for gt, pred in self.matched_pairs:
        qid = gt.get("question_id", "")

        # Filter: only summary/none
        if not (qid.endswith("_missing_summary") or qid.endswith("_missing_none")):
            skipped += 1
            continue

        # GT label
        gt_label = gt.get('label', '').strip().lower()
        gt_binary = 1 if gt_label in ['yes', 'y', 'true'] else 0

        # Pred label (from text)
        pred_text = pred.get('text', '').strip().lower()
        if 'no missing' in pred_text or 'not missing' in pred_text:
            pred_binary = 0
        elif 'missing' in pred_text:
            pred_binary = 1
        else:
            pred_binary = 0

        y_true.append(gt_binary)
        y_pred.append(pred_binary)

    # Metrics
    accuracy = accuracy_score(y_true, y_pred)
    precision, recall, f1, support = precision_recall_fscore_support(y_true, y_pred)
    cm = confusion_matrix(y_true, y_pred)
```

#### 5.2.2 Task 3: BBox Grounding

```python
# Line 320-415
def eval_bbox_grounding(self):
    """Evaluate 3D bounding box grounding"""

    for gt, pred in self.matched_pairs:
        qid = gt.get("question_id", "")

        # Filter: exclude none
        if qid.endswith("_missing_none"):
            skipped += 1
            continue

        gt_bboxes = gt.get('bboxes', [])
        if not gt_bboxes:
            skipped += 1
            continue

        # Extract predicted bboxes from text
        pred_text = pred.get('text', '')
        pred_bboxes = self.extract_bboxes_from_text(pred_text)

        # Match GT and Pred bboxes (greedy)
        for gt_bbox in gt_bboxes:
            best_iou = 0.0
            for pred_bbox in pred_bboxes:
                iou = self.calculate_iou_3d(gt_bbox, pred_bbox)
                best_iou = max(best_iou, iou)

            all_ious.append(best_iou)

            # Count success rate@IoU
            for th in [0.25, 0.5, 0.75]:
                if best_iou >= th:
                    success_at_iou[th] += 1

    # Metrics
    mean_iou = np.mean(all_ious)
    median_iou = np.median(all_ious)
    success_rate = {th: success_at_iou[th] / total_gt_bboxes for th in thresholds}
```

**BBox ì¶”ì¶œ:**
```python
def extract_bboxes_from_text(self, text: str):
    """Extract 8-corner bboxes from text using regex"""
    pattern = r'\[\s*\[\s*[-\d.]+\s*,\s*[-\d.]+\s*,\s*[-\d.]+\s*\](?:\s*,\s*\[\s*[-\d.]+\s*,\s*[-\d.]+\s*,\s*[-\d.]+\s*\])*\s*\]'

    matches = re.findall(pattern, text)

    bboxes = []
    for match in matches:
        bbox = ast.literal_eval(match)  # Safe parse
        if isinstance(bbox, list) and len(bbox) == 8:
            bboxes.append(bbox)

    return bboxes
```

**3D IoU ê³„ì‚°:**
```python
def calculate_iou_3d(self, bbox1, bbox2):
    """Calculate 3D IoU between two 8-corner bboxes"""
    # Get min/max corners
    bbox1_array = np.array(bbox1)
    bbox2_array = np.array(bbox2)

    min1 = bbox1_array.min(axis=0)
    max1 = bbox1_array.max(axis=0)
    min2 = bbox2_array.min(axis=0)
    max2 = bbox2_array.max(axis=0)

    # Intersection
    inter_min = np.maximum(min1, min2)
    inter_max = np.minimum(max1, max2)

    if np.any(inter_max <= inter_min):
        return 0.0

    inter_volume = np.prod(inter_max - inter_min)

    # Union
    vol1 = np.prod(max1 - min1)
    vol2 = np.prod(max2 - min2)
    union_volume = vol1 + vol2 - inter_volume

    return inter_volume / union_volume if union_volume > 0 else 0.0
```

#### 5.2.3 Task 5: Spatial Reasoning

```python
# Line 556-632
def eval_spatial_reasoning(self):
    """Evaluate spatial reasoning ONLY for *_missing_floor_* and *_missing_bay_*"""

    for gt, pred in self.matched_pairs:
        qid = gt['question_id']
        qtype, target = self.extract_question_type(qid)

        # Filter: only floor/bay questions
        if qtype not in ['floor', 'bay']:
            skipped += 1
            continue

        pred_text = pred.get('text', '').lower()

        # GT truth: bboxes ê¸°ë°˜ (label ì‚¬ìš© ê¸ˆì§€)
        gt_has_missing = len(gt.get('bboxes', [])) > 0

        # Pred judgement
        pred_says_no_missing = ('no missing' in pred_text) or ('not missing' in pred_text)
        pred_says_missing = ('missing' in pred_text) and (not pred_says_no_missing)

        # Spatial check: mentions floor/bay number
        mentions_target = True
        if target is not None:
            if qtype == 'floor':
                mentions_target = (str(target) in pred_text) and any(k in pred_text for k in ['floor', 'level'])
            elif qtype == 'bay':
                mentions_target = (str(target) in pred_text) and ('bay' in pred_text)

        # Correctness
        if gt_has_missing:
            correct = pred_says_missing and mentions_target
        else:
            correct = pred_says_no_missing and mentions_target

        if qtype == 'floor':
            floor_metrics[target]['correct'] += int(correct)
            floor_metrics[target]['total'] += 1
        elif qtype == 'bay':
            bay_metrics[target]['correct'] += int(correct)
            bay_metrics[target]['total'] += 1
```

### 5.3 í‰ê°€ ê²°ê³¼

```
Dataset: 5150 matched samples

TASK 1: BINARY CLASSIFICATION (ê²°ì† ìœ ë¬´)
   Accuracy: 100.00%
   Samples:  506 (201 No, 305 Yes)

TASK 2: COMPONENT TYPE CLASSIFICATION (ì–´ë–¤ íƒ€ì…?)
   Macro F1: 88.94%
   Samples:  3434

TASK 3: 3D BOUNDING BOX GROUNDING (ì–´ë””ì„œ? - 3D ì¢Œí‘œ)
   Mean IoU:          0.0105
   Success Rate@0.5:  0.42%
   Samples:           4949

TASK 4: COUNTING ACCURACY (ëª‡ ê°œ?)
   MAE:          0.542
   Exact Match:  61.79%
   Samples:      1837

TASK 5: SPATIAL REASONING (ì–´ë””ì„œ? - ì¸µ/ì—´)
   Overall: 100.00%
   Samples: 1032

TASK 6: TEMPLATE FORMAT
   Compliance: 67.89%
   Samples:    1006
```

---

## 6. ë°œê²¬ëœ ë¬¸ì œì 

### 6.1 Critical Discovery: Text Shortcut Learning

**ì‹¤í—˜: Interactive Test**

```bash
python scripts/interactive_test.py \
  --model_path ./checkpoints/shapellm-7bs-scaffold-scaffold_i3ce2-lorascaffold-i3ce_260121_1800 \
  --model_base qizekun/ShapeLLM_7B_gapartnet_v1.0 \
  --point_file ./playground/data/shapellm/scaffold_missing_complete/pcs/scaffold_02922.npy \
  --with_color
```

**ê²°ê³¼:**

| Question | Response | GT |
|----------|----------|-----|
| "Are there any missing components?" | "No missing components detected." âŒ | 4ê°œ ëˆ„ë½ (Yes) |
| "Are there missing? **If so, provide their locations.**" | "Missing: 3 components..." âœ… | 4ê°œ ëˆ„ë½ (Yes) |

**ì¦ê±°:**
1. âœ… **ë™ì¼í•œ point cloud** (scaffold_02922.npy)
2. âœ… **ì§ˆë¬¸ í…ìŠ¤íŠ¸ë§Œ ë³€ê²½** ("If so, provide locations" ìœ ë¬´)
3. âœ… **ë‹µë³€ ì™„ì „íˆ ë°˜ëŒ€** (No â†” Yes)

**â†’ ëª¨ë¸ì€ Point Cloudë¥¼ ë³´ì§€ ì•Šê³  Question Textë§Œ ë³´ê³  ë‹µë³€!**

### 6.2 Data Leakage in Question Formulation

**ë°ì´í„° ìƒì„± ì½”ë“œ ë¶„ì„:**

```python
# tools/missing_detection_dataset_final_COMPLETE_fixed.py

# Case 1: Missing components ìˆìŒ
if missing_comps:
    question = f"This is a {spec}. Are there any missing components? " \
               "If so, provide their locations."  # â† "locations" keyword!
    # â†’ í‰ê°€ ì‹œ ëª¨ë‘ Yesë¡œ ë¶„ë¥˜ë¨

# Case 2: Missing components ì—†ìŒ
else:
    question = f"This is a {spec}. Are there any missing components?"
    # â†’ "locations" ì—†ìŒ! í‰ê°€ ì‹œ ëª¨ë‘ Noë¡œ ë¶„ë¥˜ë¨
```

**Shortcut Learning Pattern:**
```python
# ëª¨ë¸ì´ í•™ìŠµí•œ ê²ƒ
if "provide their locations" in question_text:
    answer = "Missing: ..."  # Yes
else:
    answer = "No missing"     # No
```

**ì´ê²ƒì´ 100% Binary Accuracyì˜ ì§„ì§œ ì´ìœ !**

### 6.3 BBox Localization Complete Failure

**GT vs Model Prediction (scaffold_02922):**

| Component | GT | Model | Match |
|-----------|----|----|-------|
| **ê°œìˆ˜** | 4 | 3 | âŒ |
| Vertical post | column 3 | column 3 | âœ… (ìš°ì—°) |
| Horizontal floor 0 | bay 0 | - | âŒ Missing |
| Horizontal floor 2 | bay 2 | bay 1 | âŒ Wrong |
| Platform floor 1 | bay 3 | - | âŒ Missing |
| Extra | - | Horizontal floor 1 col 3 | âŒ Hallucination |

**BBox Coordinates:**
```python
# GT: Vertical post at column 3
[[0.300, -0.217, 0.120], [0.347, -0.217, 0.120], ...]

# Model Prediction
[[0.33, -0.121, 0.111], [0.37, -0.121, 0.111], ...]

# Center difference: ~0.1m in X, ~0.1m in Y
# Wrong position!
```

**Mean IoU: 0.0105** â†’ ê±°ì˜ ê²¹ì¹˜ì§€ ì•ŠìŒ (ëœë¤ ìˆ˜ì¤€)

### 6.4 Training Lossì˜ ë¬¸ì œ

**í˜„ì¬ í•™ìŠµ ë°©ì‹:**
```python
# Text generation lossë§Œ ì‚¬ìš©
loss = CrossEntropy(predicted_text, gt_text)

# BBoxëŠ” text tokenìœ¼ë¡œë§Œ í•™ìŠµ
# "[[0.3, -0.2, 0.1], ...]" â†’ tokenize â†’ generate
# â†’ ìˆ«ìë¥¼ ì •í™•íˆ ë§ì¶°ì•¼ í•¨ (ë„ˆë¬´ ì–´ë ¤ì›€!)
```

**ë¬¸ì œ:**
1. BBoxë¥¼ textë¡œ í•™ìŠµ â†’ 3D spatial understanding ì—†ìŒ
2. ê° ìˆ«ìê°€ ì •í™•í•´ì•¼ í•¨ â†’ Token-level lossëŠ” ë¶€ì ì ˆ
3. IoU loss, coordinate regression loss ë“± ì—†ìŒ
4. â†’ BBox ì •í™•ë„ ê·¹ë„ë¡œ ë‚®ìŒ (0.42%)

### 6.5 Point Cloud Utilization ì˜ë¬¸

**ì¦ê±°ë“¤:**
1. Text shortcutìœ¼ë¡œ 100% binary accuracy
2. BBox ê±°ì˜ í‹€ë¦¼ (0.42% IoU@0.5)
3. Interactive testì—ì„œ ì§ˆë¬¸ë§Œ ë°”ê¾¸ë©´ ë‹µë³€ ë°˜ëŒ€

**ê°€ëŠ¥ì„±:**
- âŒ Point cloudë¥¼ ì „í˜€ ì•ˆ ë´„
- âš ï¸ Global featureë§Œ ë´„ (ì „ì²´ ì  ê°œìˆ˜, ë°€ë„)
- âŒ Local spatial structureëŠ” ì´í•´ ëª» í•¨

---

## 7. ê·¼ë³¸ ì›ì¸ ë¶„ì„

### 7.1 Data Leakage

**Question Formulation Bias:**
```
Training Distribution:
â”œâ”€â”€ "...If so, provide their locations." â†’ 100% Yes (has missing)
â””â”€â”€ "...Are there any missing?"         â†’ 100% No (no missing)

Model learns:
if "locations" in text:
    return "Missing: ..."
else:
    return "No missing"
```

**ì´ê²ƒì€ í•™ìŠµì´ ì•„ë‹ˆë¼ pattern matching!**

### 7.2 Loss Function Inadequacy

**Text-only Loss:**
```python
loss = CrossEntropy(tokens)  # Only text generation

# No spatial loss:
# - No IoU loss
# - No coordinate regression loss
# - No structure awareness loss
```

**â†’ 3D understanding í•™ìŠµ ì•ˆ ë¨!**

### 7.3 Evaluation Protocol Flaw

**ë¬¸ì œ:**
1. Question IDê°€ task type í¬í•¨ (_summary, _none)
2. Question textê°€ answer ì•”ì‹œ ("locations")
3. Ablation study ì—†ìŒ

**â†’ Shortcut learning ê°ì§€ ì‹¤íŒ¨!**

---

## 8. í•™ìˆ ì  ë¶„ì„

### 8.1 Shortcut Learning

**ì •ì˜:**
> Models exploit spurious correlations in training data instead of learning intended task.

**ë³¸ ì—°êµ¬ì—ì„œ:**
```
Intended: Point cloud â†’ Missing detection
Actual:   Question text pattern â†’ Answer template
```

**ì°¸ê³  ë¬¸í—Œ:**
- Geirhos et al., "Shortcut Learning in Deep Neural Networks" (Nature MI, 2020)
- McCoy et al., "Right for the Wrong Reasons" (ACL 2019)

### 8.2 Data Leakage

**ì •ì˜:**
> Information from target variable leaks into input features during training.

**ë³¸ ì—°êµ¬ì—ì„œ:**
```
Target: Yes/No (missing detection)
Leak:   Question text contains "locations" iff target=Yes
```

**Impact:**
- Model achieves 100% without visual reasoning
- Generalizes poorly to real deployment (no question patterns)

### 8.3 Multi-Task Learning Failure

**6 Tasks í‰ê°€:**

| Task | Metric | Visual Dependency | ì‹¤ì œ ì„±ëŠ¥ |
|------|--------|-------------------|----------|
| Binary | 100% | Low | **0%** (text shortcut) |
| Type | 89% | Medium | **ì˜ì‹¬** (text keywords) |
| BBox | 0.42% | **High** | **0%** (random) |
| Count | 62% | Medium | **ë¶ˆëª…** |
| Spatial | 100% | High | **ì˜ì‹¬** (text shortcut) |
| Format | 68% | Low | **ë¶ˆëª…** |

**ê²°ë¡ :** Visual grounding ê±°ì˜ í•™ìŠµ ì•ˆ ë¨!

### 8.4 Vision-Language Alignment Gap

**Expected:**
```
Point Cloud â†’ Vision Encoder â†’ Features â†’ LLM â†’ Answer
                                 â†‘
                        Visual grounding
```

**Actual:**
```
Point Cloud â†’ (ignored)
Question Text â†’ Pattern Match â†’ Answer Template
```

**â†’ Vision-Language alignment ì‹¤íŒ¨!**

---

## 9. í•´ê²° ë°©ì•ˆ

### 9.1 Immediate Fix: Question Reformulation

**ë°ì´í„° ì¬ìƒì„±:**

```python
# Before (ë¬¸ì œ)
if has_missing:
    question = "...If so, provide their locations."  # Leak!
else:
    question = "...Are there any missing?"

# After (ìˆ˜ì •)
# ëª¨ë“  ì§ˆë¬¸ ë™ì¼í•˜ê²Œ
question = "This is a {spec}. Are there any missing components? " \
           "If so, provide their locations."

# Answerë§Œ ë‹¤ë¦„
if has_missing:
    answer = "Missing: ..."
else:
    answer = "No missing components detected."
```

**ëª…ë ¹ì–´:**
```bash
# 1. ë°ì´í„° ìƒì„± ì½”ë“œ ìˆ˜ì •
# tools/missing_detection_dataset_final_COMPLETE_fixed.py ìˆ˜ì •

# 2. ë°ì´í„° ì¬ìƒì„±
python tools/missing_detection_dataset_final_COMPLETE_fixed.py \
  --num-scenes 3000 \
  --train-ratio 0.8 \
  --val-ratio 0.2 \
  --output-dir ./playground/data/shapellm/scaffold_missing_complete_v2

# 3. ì¬í•™ìŠµ
bash scripts/finetune_lora_test.sh  # ë°ì´í„° ê²½ë¡œ ìˆ˜ì • í•„ìš”
```

### 9.2 Training Improvement: Multi-Task Loss

**Separate BBox Loss:**

```python
# Current (text-only)
loss = text_loss

# Proposed (multi-task)
loss = text_loss + Î»_bbox * bbox_loss + Î»_iou * iou_loss

# BBox regression loss
bbox_loss = MSE(pred_coords, gt_coords)

# IoU loss (differentiable)
iou_loss = 1 - IoU(pred_bbox, gt_bbox)

# Weight: Î»_bbox=1.0, Î»_iou=10.0
```

**êµ¬í˜„:**
```python
# llava/train/train.py ìˆ˜ì • í•„ìš”

class ScaffoldLoss(nn.Module):
    def __init__(self):
        self.text_loss = CrossEntropyLoss()
        self.bbox_loss = MSELoss()

    def forward(self, outputs, targets):
        # Text generation loss
        text_loss = self.text_loss(outputs['logits'], targets['labels'])

        # Extract bbox predictions from text
        pred_bboxes = extract_bboxes_from_generated_text(outputs['text'])
        gt_bboxes = targets['bboxes']

        # BBox loss
        if pred_bboxes and gt_bboxes:
            bbox_loss = self.compute_bbox_loss(pred_bboxes, gt_bboxes)
        else:
            bbox_loss = 0.0

        return text_loss + 10.0 * bbox_loss
```

### 9.3 Evaluation Improvement: Ablation Studies

**í•„ìˆ˜ ì‹¤í—˜:**

**1. Point Cloud Ablation:**
```bash
# Test A: Normal point cloud
python inference.py --point-file scaffold_02922.npy

# Test B: Random noise
python inference.py --point-file random_noise.npy

# Test C: Empty/zeros
python inference.py --point-file zeros.npy

# If A == B == C â†’ Not using point cloud!
```

**2. Text-Only Baseline:**
```bash
# Inference without point cloud features
python inference.py --disable-vision

# Compare accuracy with full model
# If similar â†’ Text shortcut confirmed!
```

**3. Cross-Dataset Test:**
```bash
# Train: scaffold_A
# Test:  scaffold_B (different structure)

# If performance drops significantly â†’ Overfitting patterns
```

### 9.4 Architecture Improvement

**Option 1: Auxiliary Tasks**
```python
# Add explicit spatial reasoning tasks
tasks = [
    "Which floor is this component on?",
    "Which bay is this component in?",
    "What is the 3D center of this bbox?"
]

# Multi-task learning with auxiliary supervision
```

**Option 2: Stronger Point Cloud Encoder**
```python
# Current: ReCon V2 (512 groups)
# Upgrade: Point Transformer V2/V3
# Or: PointNet++ with more layers
```

**Option 3: Structured Output**
```python
# Instead of free-form text:
output = {
    "has_missing": bool,
    "count": int,
    "components": [
        {
            "type": "vertical/horizontal/platform",
            "location": {"floor": int, "bay": int},
            "bbox": [[x,y,z], ...]
        }
    ]
}

# Easier to train and evaluate!
```

---

## 10. ì½”ë“œ ìˆ˜ì • ì´ë ¥

### 10.1 Point Cloud Generation ê°œì„ 

**Commit:** `84053b7` - Fix point cloud sparsity

**ë¬¸ì œ:** Beamì´ ë„ì—„ë„ì—„ 10ê°œ êµ¬ê°„ì—ë§Œ ì ì´ ë­‰ì³ìˆìŒ

**ì›ì¸:**
```python
# Before
for i in range(50):
    if i % 5 == 0:  # Only 10 positions!
        for j in range(8):
            points.append(...)
```

**ìˆ˜ì •:**
```python
# After
for i in range(num_points):  # All positions
    for j in range(8):
        noise = np.random.normal(0, 0.005, 3)
        points.append(center + offset + noise)
```

### 10.2 Adaptive Sampling ì¶”ê°€

**Commit:** `9a4d397` - Improve point cloud detail

**Before:**
```python
# Fixed 50 points for all pipes
def generate_pipe_points(start, end, diameter, num_points=50):
    ...
```

**After:**
```python
# Length-based adaptive sampling
def generate_pipe_points(start, end, diameter, num_points=None):
    if num_points is None:
        length = np.linalg.norm(end - start)
        num_points = max(int(length * 100), 10)  # ê¸¸ì´ ë¹„ë¡€
        num_points = min(num_points, 200)         # Cap at 200
```

**ê²°ê³¼:**
- ì§§ì€ beam (0.5m): 50ì  Ã— 8ê°ë„ = 400ì 
- ê¸´ beam (2.0m): 200ì  Ã— 8ê°ë„ = 1600ì 

### 10.3 Evaluation ì½”ë“œ ìˆ˜ì •

**Commit:** `8e0651e` - Fix evaluation code

**ìˆ˜ì • 1: eval() â†’ ast.literal_eval()**
```python
# Before (ë³´ì•ˆ ìœ„í—˜)
bbox = eval(match)

# After (ì•ˆì „)
bbox = ast.literal_eval(match)
```

**ìˆ˜ì • 2: Metric ì´ë¦„ ì •ì •**
```python
# Before (í‹€ë¦° ëª…ì¹­)
precision_at_iou = {...}
results[f'precision@{th}'] = ...

# After (ì •í™•í•œ ëª…ì¹­)
success_at_iou = {...}
results[f'success_rate@{th}'] = ...  # GT-based recall
```

**ìˆ˜ì • 3: Task 5 label ì œê±°**
```python
# Before (label ì‚¬ìš© - ì›ì¹™ ìœ„ë°˜)
gt_label = gt.get('label', '').lower()
if gt_label == 'yes':
    correct = ...

# After (bboxes ê¸°ë°˜)
gt_has_missing = len(gt.get('bboxes', [])) > 0
if gt_has_missing:
    correct = pred_says_missing and mentions_target
```

**ìˆ˜ì • 4: Filter rule ì •í™•í™”**
```python
# Before (ë¶ˆì¼ì¹˜)
'filter_rule': "Exclude: *_missing_none only"

# After (ì •í™•)
'filter_rule': "Use samples with gt_bboxes only (skips *_missing_none and any gt_bboxes=[])"
```

---

## ğŸ“Œ ê²°ë¡  ë° ê¶Œê³ ì‚¬í•­

### í˜„ì¬ ìƒíƒœ

| í•­ëª© | ìƒíƒœ | ì„¤ëª… |
|------|------|------|
| **ë°ì´í„° ìƒì„±** | âŒ | Question formulation bias (data leakage) |
| **ëª¨ë¸ í•™ìŠµ** | âŒ | Text shortcut learning (no visual grounding) |
| **í‰ê°€ ê²°ê³¼** | âš ï¸ | 100% binaryëŠ” í—ˆìƒ, BBox 0.42% |
| **ë°°í¬ ê°€ëŠ¥ì„±** | âŒ | ì•ˆì „ ê²€ì‚¬ ë¶ˆê°€ëŠ¥ (point cloud ì•ˆ ë´„) |

### ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš”

1. âœ… **ë¬¸ì œ ì¸ì •** - í•™ìˆ ì ìœ¼ë¡œ ì •ì§í•˜ê²Œ ë³´ê³ 
2. ğŸ”„ **ë°ì´í„° ì¬ìƒì„±** - Question text í†µì¼
3. ğŸ”„ **ì¬í•™ìŠµ í•„ìš”** - ì˜¬ë°”ë¥¸ ë°ì´í„°ë¡œ
4. ğŸ”¬ **Ablation study** - Point cloud dependency ê²€ì¦

### í•™ìˆ  ë…¼ë¬¸ ì‘ì„± ì‹œ

**âŒ ì ˆëŒ€ ì“°ë©´ ì•ˆ ë˜ëŠ” í‘œí˜„:**
> "Our model achieves 100% binary classification accuracy."

**âœ… ì •ì§í•œ í‘œí˜„:**
> "Initial evaluation showed 100% accuracy, but ablation studies revealed text-based shortcut learning. We identified question formulation bias and propose solutions."

### ë°°í¬ ì „ í•„ìˆ˜ ì‚¬í•­

1. Question reformulation + ì¬í•™ìŠµ
2. Text-only baseline ë¹„êµ ì‹¤í—˜
3. Point cloud ablation ì‹¤í—˜
4. Real-world test (ì‹¤ì œ ë¹„ê³„ ì êµ°)

**í˜„ì¬ ëª¨ë¸ì€ ë°°í¬ ë¶ˆê°€!** âš ï¸

---

**ë³´ê³ ì„œ ì¢…ë£Œ**
