#!/usr/bin/env python3
"""ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸"""

import json
import numpy as np
from pathlib import Path
import sys

def verify_dataset(data_dir):
    """ë°ì´í„°ì…‹ ê²€ì¦"""
    data_dir = Path(data_dir)

    print("ðŸ” ë°ì´í„°ì…‹ ê²€ì¦ ì‹œìž‘...")
    print("=" * 60)

    errors = []
    warnings = []

    # 1. í•„ìˆ˜ íŒŒì¼ í™•ì¸
    print("\n1. í•„ìˆ˜ íŒŒì¼ í™•ì¸:")
    required_files = ['split.json', 'metadata.json', 'instructions_train.json']
    for f in required_files:
        if (data_dir / f).exists():
            print(f"   âœ… {f}")
        else:
            errors.append(f"Missing: {f}")
            print(f"   âŒ {f}")

    # 2. split.json ê²€ì¦
    print("\n2. Split ê²€ì¦:")
    try:
        split = json.load(open(data_dir / 'split.json'))
        total = len(split['train']) + len(split['val']) + len(split['test'])
        print(f"   Train: {len(split['train'])} ({len(split['train'])/total*100:.1f}%)")
        print(f"   Val:   {len(split['val'])} ({len(split['val'])/total*100:.1f}%)")
        print(f"   Test:  {len(split['test'])} ({len(split['test'])/total*100:.1f}%)")

        # ì¤‘ë³µ í™•ì¸
        all_ids = split['train'] + split['val'] + split['test']
        if len(all_ids) != len(set(all_ids)):
            errors.append("Duplicate scene IDs in split")
    except Exception as e:
        errors.append(f"Split validation failed: {e}")

    # 3. Point cloud ê²€ì¦
    print("\n3. Point cloud ê²€ì¦:")
    pcs_dir = data_dir / 'pcs'
    if pcs_dir.exists():
        npy_files = list(pcs_dir.glob('*.npy'))
        print(f"   Total files: {len(npy_files)}")

        # ìƒ˜í”Œ ê²€ì¦
        if npy_files:
            sample = np.load(npy_files[0])
            print(f"   Shape: {sample.shape}")
            print(f"   Dtype: {sample.dtype}")
            print(f"   Range: [{sample.min():.3f}, {sample.max():.3f}]")

            if sample.shape[1] != 3:
                errors.append(f"Point cloud should be (N, 3), got {sample.shape}")
            if sample.dtype != np.float32:
                warnings.append(f"Point cloud should be float32, got {sample.dtype}")
    else:
        errors.append("pcs/ directory not found")

    # 4. Annotations ê²€ì¦
    print("\n4. Annotations ê²€ì¦:")
    try:
        train_ann = json.load(open(data_dir / 'instructions_train.json'))
        print(f"   Train annotations: {len(train_ann)}")

        # ì²« ë²ˆì§¸ ìƒ˜í”Œ êµ¬ì¡° í™•ì¸
        if train_ann:
            sample = train_ann[0]
            required_keys = ['id', 'point', 'conversations']
            for key in required_keys:
                if key not in sample:
                    errors.append(f"Annotation missing key: {key}")
                else:
                    print(f"   âœ… {key}: {type(sample[key]).__name__}")

            # Conversation êµ¬ì¡° í™•ì¸
            if 'conversations' in sample and sample['conversations']:
                conv = sample['conversations'][0]
                if 'from' in conv and 'value' in conv:
                    print(f"   âœ… Conversation format correct")
                else:
                    errors.append("Conversation format incorrect")
    except Exception as e:
        errors.append(f"Annotation validation failed: {e}")

    # 5. Meta/Labels ê²€ì¦
    print("\n5. Meta & Labels ê²€ì¦:")
    meta_dir = data_dir / 'meta'
    labels_dir = data_dir / 'labels'

    if meta_dir.exists() and labels_dir.exists():
        meta_files = list(meta_dir.glob('*.json'))
        label_files = list(labels_dir.glob('*.json'))
        print(f"   Meta files: {len(meta_files)}")
        print(f"   Label files: {len(label_files)}")

        # ìƒ˜í”Œ ê²€ì¦
        if meta_files:
            meta = json.load(open(meta_files[0]))
            if 'norm_params' in meta:
                norm = meta['norm_params']
                print(f"   âœ… Norm params: centroid, scale, Rz_deg")
                print(f"      Scale: {norm.get('scale', 'N/A'):.3f}")
            else:
                warnings.append("Meta missing norm_params")

        if label_files:
            labels = json.load(open(label_files[0]))
            if labels:
                label = labels[0]
                if 'bbox_world' in label and 'bbox_norm' in label:
                    print(f"   âœ… Dual bbox format")
                else:
                    warnings.append("Label missing dual bbox")
    else:
        warnings.append("meta/ or labels/ directory not found")

    # ìµœì¢… ê²°ê³¼
    print("\n" + "=" * 60)
    if errors:
        print("âŒ ê²€ì¦ ì‹¤íŒ¨:")
        for err in errors:
            print(f"   - {err}")
        return False
    elif warnings:
        print("âš ï¸  ê²½ê³  ì‚¬í•­:")
        for warn in warnings:
            print(f"   - {warn}")
        print("\nâœ… ê²€ì¦ í†µê³¼ (ê²½ê³  ìžˆìŒ)")
        return True
    else:
        print("âœ… ì™„ë²½í•œ ë°ì´í„°ì…‹!")
        return True

if __name__ == "__main__":
    data_dir = sys.argv[1] if len(sys.argv) > 1 else "./playground/data/shapellm/scaffold_sft_color"
    success = verify_dataset(data_dir)
    sys.exit(0 if success else 1)
